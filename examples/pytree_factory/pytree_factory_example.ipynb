{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "import equinox as eqx\n",
    "\n",
    "from ml_templates.pytree_factory import PyTreeFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use `PyTreeFactory`\n",
    "\n",
    "Make a factory for neural networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mlp(**kwargs):\n",
    "    if 'seed' not in kwargs:\n",
    "        kwargs['seed'] = 0\n",
    "    if 'activation' not in kwargs:\n",
    "        kwargs['activation'] = jax.nn.gelu\n",
    "    kwargs['key'] = jrandom.PRNGKey(kwargs.pop('seed'))\n",
    "    return eqx.nn.MLP(**kwargs)\n",
    "\n",
    "nn_factory = PyTreeFactory()\n",
    "nn_factory.register_generator('mlp', make_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This factory (as of now) has only one thing it can generate&mdash;an MLP.\n",
    "\n",
    "Let's also make a factory for input/output scalers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler(eqx.Module):\n",
    "    \"\"\"Standardize input data by removing the mean and scaling to unit variance.\"\"\"\n",
    "    mean: float = eqx.field(default_factory=lambda: jnp.array(0.0))\n",
    "    std: float = eqx.field(default_factory=lambda: jnp.array(1.0))\n",
    "\n",
    "    @classmethod\n",
    "    def fit(cls, data, axis=None):\n",
    "        mean = data.mean(axis=axis)\n",
    "        std = data.std(axis=axis)\n",
    "        return cls(mean, std)\n",
    "\n",
    "    def forward(self, data):\n",
    "        return (data - self.mean) / self.std\n",
    "\n",
    "    def inverse(self, data):\n",
    "        return data * self.std + self.mean\n",
    "\n",
    "def make_standard_scaler(shape=()):\n",
    "    return StandardScaler(mean=jnp.zeros(shape), std=jnp.ones(shape))\n",
    "\n",
    "scaler_factory = PyTreeFactory()\n",
    "scaler_factory.register_generator('standard', StandardScaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this factory can only make one thing&mdash;a standard scaler (i.e., a function that normalizes it's inputs).\n",
    "\n",
    "Let's make a factory for what we'll call \"unscaled\" models.\n",
    "By \"unscaled\" model, we mean a function that takes an input, scales it, passes it through a NN, and then unscales it.\n",
    "Note that this factory depends on the output of the NN factory and the scaler factory.\n",
    "So, we will need to create a nested factory pattern to obey this dependency.\n",
    "We do this by *subclassing* the `PyTreeFactory` class.\n",
    "\n",
    "Here is how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, as before, define the type object the factory will produce.\n",
    "class UnscaledModel(eqx.Module):\n",
    "    \"\"\"A model that scales its input before passing it to another model.\"\"\"\n",
    "    scaled_model: callable\n",
    "    input_scaler: callable\n",
    "    output_scaler: callable\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.input_scaler.forward(x)\n",
    "        x = self.scaled_model(x)\n",
    "        return self.output_scaler.inverse(x)\n",
    "\n",
    "# Next, subclass PyTreeFactory to create a factory that is dependent on another factory.\n",
    "class ModelFactory(PyTreeFactory):\n",
    "    def __init__(self):\n",
    "        self.parent_factories = {\"nn\": nn_factory, \"scaler\": scaler_factory}\n",
    "        self.generators = {\"unscaled_model\": self.make_unscaled_model}\n",
    "\n",
    "    def make_unscaled_model(\n",
    "        self,\n",
    "        scaled_model_gen_name,\n",
    "        scaled_model_hyperparams,\n",
    "        input_scaler_gen_name,\n",
    "        input_scaler_hyperparams,\n",
    "        output_scaler_gen_name,\n",
    "        output_scaler_hyperparams,\n",
    "    ):  \n",
    "        # Use factory to generate the contents of the unscaled model\n",
    "        scaled_model = self.parent_factories[\"nn\"].generate(scaled_model_gen_name, scaled_model_hyperparams)\n",
    "        input_scaler = self.parent_factories[\"scaler\"].generate(input_scaler_gen_name, input_scaler_hyperparams)\n",
    "        output_scaler = self.parent_factories[\"scaler\"].generate(output_scaler_gen_name, output_scaler_hyperparams)\n",
    "        \n",
    "        # Create unscaled model\n",
    "        return UnscaledModel(scaled_model=scaled_model, input_scaler=input_scaler, output_scaler=output_scaler)\n",
    "    \n",
    "# Finally, initialize the factory.\n",
    "model_factory = ModelFactory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our newly created model factory to generate a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnscaledModel(\n",
       "  scaled_model=MLP(\n",
       "    layers=(\n",
       "      Linear(\n",
       "        weight=f32[30,3],\n",
       "        bias=f32[30],\n",
       "        in_features=3,\n",
       "        out_features=30,\n",
       "        use_bias=True\n",
       "      ),\n",
       "      Linear(\n",
       "        weight=f32[30,30],\n",
       "        bias=f32[30],\n",
       "        in_features=30,\n",
       "        out_features=30,\n",
       "        use_bias=True\n",
       "      ),\n",
       "      Linear(\n",
       "        weight=f32[30,30],\n",
       "        bias=f32[30],\n",
       "        in_features=30,\n",
       "        out_features=30,\n",
       "        use_bias=True\n",
       "      ),\n",
       "      Linear(\n",
       "        weight=f32[2,30],\n",
       "        bias=f32[2],\n",
       "        in_features=30,\n",
       "        out_features=2,\n",
       "        use_bias=True\n",
       "      )\n",
       "    ),\n",
       "    activation=<function gelu>,\n",
       "    final_activation=<function <lambda>>,\n",
       "    use_bias=True,\n",
       "    use_final_bias=True,\n",
       "    in_size=3,\n",
       "    out_size=2,\n",
       "    width_size=30,\n",
       "    depth=3\n",
       "  ),\n",
       "  input_scaler=StandardScaler(mean=[1.0, 2.0, 3.0], std=0.1),\n",
       "  output_scaler=StandardScaler(mean=[100.0, 200.0, 300.0], std=10.0)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_model_hyperparams = dict(\n",
    "    scaled_model_gen_name=\"mlp\",\n",
    "    scaled_model_hyperparams=dict(in_size=3, out_size=2, width_size=30, depth=3),\n",
    "    input_scaler_gen_name=\"standard\",\n",
    "    input_scaler_hyperparams=dict(mean=[1., 2., 3.], std=0.1),\n",
    "    output_scaler_gen_name=\"standard\",\n",
    "    output_scaler_hyperparams=dict(mean=[100., 200., 300.], std=10.0),\n",
    ")\n",
    "unscaled_model = model_factory.generate(\"unscaled_model\", unscaled_model_hyperparams)\n",
    "unscaled_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the nice things about this factory pattern is that we can easily save and load models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_factory.save_pytree(unscaled_model, \"unscaled_model.eqx\", \"unscaled_model\", unscaled_model_hyperparams)\n",
    "loaded_unscaled_model = model_factory.load_pytree(\"unscaled_model.eqx\")\n",
    "eqx.tree_equal(unscaled_model, loaded_unscaled_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
